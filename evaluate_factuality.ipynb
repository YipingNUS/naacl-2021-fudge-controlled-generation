{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import math\n",
    "from argparse import ArgumentParser\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizerFast, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "\n",
    "from data import Dataset\n",
    "from model import Model\n",
    "from util import save_checkpoint, ProgressMeter, AverageMeter, num_params\n",
    "from constants import *\n",
    "from predict_factuality import predict_factuality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = 'patrickvonplaten/bert2bert_cnn_daily_mail'\n",
    "attribute_model_string = 'textattack/bert-base-uncased-MNLI'\n",
    "device = 'cuda'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model: patrickvonplaten/bert2bert_cnn_daily_mail...\n",
      "Loading pre-trained conditioning model: textattack/bert-base-uncased-MNLI...\n",
      "model num params 247363386\n",
      "conditioning_model num params 109484547\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(model_string)\n",
    "print(f\"Loading pre-trained model: {model_string}...\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_string, return_dict=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loading pre-trained conditioning model: {attribute_model_string}...\")\n",
    "conditioning_model = AutoModelForSequenceClassification.from_pretrained(attribute_model_string).to(device)\n",
    "conditioning_model.eval()\n",
    "if verbose:\n",
    "    #checkpoint = torch.load(args.ckpt, map_location=args.device)\n",
    "    #print(f\"=> loaded checkpoint '{args.ckpt}' (epoch {checkpoint['epoch']})\")\n",
    "    print(f\"model num params {num_params(model)}\")\n",
    "    print(f\"conditioning_model num params {num_params(conditioning_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "with open('factuality_data/dummy_input.txt', 'r', encoding='utf-8') as rf:\n",
    "    for line in rf:\n",
    "        inputs.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the eiffel tower is the tallest structure in paris. it is the second tallest structure to reach a height of 300 metres. the tower is now taller than the chrysler building. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for inp in tqdm(inputs, total=len(inputs)):\n",
    "    results = predict_factuality(model,\n",
    "                    tokenizer, \n",
    "                    conditioning_model, \n",
    "                    [inp],\n",
    "                    precondition_topk=200,\n",
    "                    do_sample=False,\n",
    "                    min_length=30,\n",
    "                    max_length=90,\n",
    "                    condition_lambda=0.0,\n",
    "                    device=device)\n",
    "    print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
